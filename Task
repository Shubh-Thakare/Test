hii/* Sort the DataFrame by ContractNumber and EffectiveDate */
proc sort data=YourDataFrame;
  by ContractNumber EffectiveDate;
run;

/* Create a new DataFrame with forward filled values */
data ForwardFilledDataFrame;
  set YourDataFrame;
  by ContractNumber EffectiveDate;

  /* Retain the last non-missing values within the same ContractNumber */
  retain LastCompanyName LastEffectiveDate;

  /* Update the retained values */
  if first.ContractNumber then do;
    LastCompanyName = CompanyName;
    LastEffectiveDate = EffectiveDate;
  end;

  /* Forward fill missing values with the retained values */
  if missing(CompanyName) then CompanyName = LastCompanyName;
  if missing(EffectiveDate) then EffectiveDate = LastEffectiveDate;

  /* Output the updated row */
  output;
  
  /* Clear retained values for the next iteration */
  if last.ContractNumber then call missing(LastCompanyName, LastEffectiveDate);
run;

/* Sort the ForwardFilledDataFrame by ContractNumber and EffectiveDate if necessary */
proc sort data=ForwardFilledDataFrame;
  by ContractNumber EffectiveDate;
run;





import pandas as pd

# Sample DataFrame
data = {
    'date': ['2023-01-01', '2023-01-02', '2023-01-03', '2023-01-04', '2023-01-05', '2023-01-06', '2023-01-07', '2023-01-08'],
    'column_with_duplicates': ['A', 'B', 'A', 'A', 'C', 'C', 'C', 'D']
}

df = pd.DataFrame(data)

# Step 1: Sort the DataFrame by the date column
df.sort_values(by='date', inplace=True)

# Step 2: Identify and mark duplicates in the specified column
df['is_duplicate'] = df['column_with_duplicates'].duplicated(keep='first')

# Step 3: Keep first occurrence of duplicates if they are in continuous rows, otherwise keep all duplicates
df['is_duplicate'] = df['is_duplicate'] & df['is_duplicate'].shift(-1, fill_value=False)

# Step 4: Drop the marked duplicate rows
result_df = df[~df['is_duplicate']].drop(columns=['is_duplicate'])

print(result_df)




import pandas as pd

# Sample DataFrame
data = {
    'date': ['2023-01-01', '2023-01-02', '2023-01-03', '2023-01-03', '2023-01-04', '2023-01-05', '2023-01-05'],
    'value': [1, 2, 3, 3, 4, 5, 5]
}

df = pd.DataFrame(data)

# Convert the 'date' column to datetime
df['date'] = pd.to_datetime(df['date'])

# Step 1: Sort the DataFrame by the 'date' column
df.sort_values(by='date', inplace=True)

# Step 2: Identify duplicates in the 'value' column
duplicates_mask = df['value'].duplicated(keep='first')

# Step 3: Keep the first row of each set of continuous duplicates and drop the rest
result_df = df[~(duplicates_mask & duplicates_mask.shift(-1))]

print(result_df)







import pandas as pd

# Sample DataFrame (replace this with your actual DataFrame)
data = {
    'date': ['2023-01-01', '2023-01-02', '2023-01-03', '2023-01-04', '2023-01-04', '2023-01-06', '2023-01-07'],
    'value': [1, 2, 3, 4, 4, 6, 7]
}

df = pd.DataFrame(data)

# Convert the 'date' column to datetime
df['date'] = pd.to_datetime(df['date'])

# Sort the DataFrame by the 'date' column
df.sort_values(by='date', inplace=True)

# Identify duplicates in the 'value' column
duplicates_mask = df['value'].duplicated(keep=False)

# Keep the first occurrence of duplicates if they are in continuous rows; otherwise, keep all duplicates
result_df = df.drop_duplicates(subset='value', keep='first' if duplicates_mask.all() else False)

print(result_df)









import pandas as pd

# Sample DataFrame (replace this with your actual DataFrame)
data = {
    'date': ['2023-01-01', '2023-01-02', '2023-01-03', '2023-01-04', '2023-01-05', '2023-01-06'],
    'column_with_duplicates': ['A', 'B', 'B', 'C', 'C', 'D']
}

df = pd.DataFrame(data)

# Step 1: Sort the DataFrame by the date column
df.sort_values(by='date', inplace=True)

# Step 2: Identify duplicates in the specified column
duplicates_mask = df['column_with_duplicates'].duplicated(keep='first')

# Step 3: Keep the first occurrence of duplicates only if they appear in continuous rows
df.drop_duplicates(subset='column_with_duplicates', keep='first', inplace=True, ignore_index=True)

# Output the final DataFrame
print(df







import pandas as pd

# Sample DataFrame (replace this with your actual DataFrame)
data = {
    'contract': ['A', 'A', 'B', 'B', 'B', 'C', 'C', 'C'],
    'date': ['2023-01-01', '2023-01-02', '2023-01-03', '2023-01-04', '2023-01-05', '2023-01-06', '2023-01-07', '2023-01-08'],
    'value': [10, 15, 20, 20, 25, 30, 35, 40]
}

df = pd.DataFrame(data)

# Identify duplicates in the 'contract' column
duplicates_mask = df['contract'].duplicated(keep='first')

# Iterate through the DataFrame and drop duplicates based on the specified conditions
rows_to_drop = []
for i in range(len(df)):
    if duplicates_mask[i]:
        # Check if the duplicate values are continuous
        if df['contract'][i] == df['contract'][i - 1]:
            rows_to_drop.append(i)
    else:
        # Reset the continuous duplicates flag
        continuous_duplicates = False

# Drop the identified duplicate rows
df_cleaned = df.drop(rows_to_drop)

# Output the cleaned DataFrame
print(df_cleaned)







from pptx import Presentation
from pptx.util import Inches

# Open the existing PowerPoint template
template_path = "path_to_your_template.potx"
prs = Presentation(template_path)

# Add a new slide with a title and content layout
slide_layout = prs.slide_layouts[5]
slide = prs.slides.add_slide(slide_layout)

# Define the number of rows and columns for the table
rows = 4
cols = 3

# Add a table to the slide
left = Inches(1)
top = Inches(2)
width = Inches(6)
height = Inches(2)
table = slide.shapes.add_table(rows, cols, left, top, width, height).table

# Populate the table with values
table.cell(0, 0).text = "Header 1"
table.cell(0, 1).text = "Header 2"
table.cell(0, 2).text = "Header 3"

# Add values to the table cells
data = [
    [1, "A", "X"],
    [2, "B", "Y"],
    [3, "C", "Z"],
    [4, "D", "W"]
]

for row_index, row in enumerate(data):
    for col_index, value in enumerate(row):
        table.cell(row_index + 1, col_index).text = str(value)

# Save the modified presentation
prs.save("modified_presentation.pptx")









import streamlit as st

# Use st.write() to print something to the app
st.write("Hello, Streamlit!")

import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt

# Display text
st.text("This is some text.")

# Display a data frame
data = {'Column 1': [1, 2, 3, 4],
        'Column 2': [10, 20, 15, 25]}
df = pd.DataFrame(data)
st.dataframe(df)

# Display a matplotlib plot
plt.plot(data['Column 1'], data['Column 2'])
st.pyplot(plt)

# Display a button
if st.button('Click me!'):
    st.write('Button clicked!')










import pandas as pd
from pptx import Presentation
from pptx.util import Inches
from pptx.enum.text import PP_ALIGN
from pptx.enum.chart import XL_CHART_TYPE

# Load your DataFrame (example)
data = {
    'Category': ['A', 'B', 'C', 'D'],
    'Value': [10, 15, 8, 12]
}
df = pd.DataFrame(data)

# Load the existing PowerPoint presentation
presentation_path = 'path/to/your/presentation.pptx'
prs = Presentation(presentation_path)

# Create a slide for the chart
slide_layout = prs.slide_layouts[1]  # Use the appropriate slide layout index according to your template
slide = prs.slides.add_slide(slide_layout)

# Define chart data
categories = df['Category'].tolist()
values = df['Value'].tolist()

# Create a chart on the slide
left = Inches(1)  # Adjust the position as needed
top = Inches(1)
width = Inches(6)  # Adjust the width as needed
height = Inches(4)  # Adjust the height as needed
chart = slide.shapes.add_chart(
    XL_CHART_TYPE.BAR_CLUSTERED, left, top, width, height
).chart

# Add data to the chart
chart.has_legend = False  # You can set this to True if you want to display legends
chart_data = pd.Series(values, index=categories)
chart_data_plt = chart.plots[0]
chart_data_plt.replace_data(chart_data)

# Customize the appearance of the chart
category_axis = chart.category_axis
category_axis.has_major_gridlines = True
category_axis.tick_labels.font.size = Pt(10)  # Set the font size of category labels
category_axis.tick_labels.number_format = '0'  # Set the number format of category labels

value_axis = chart.value_axis
value_axis.has_major_gridlines = True

# Save the modified presentation
prs.save('path/to/modified_presentation.pptx')







import pandas as pd
from pptx import Presentation
from pptx.util import Inches
from pptx.chart.data import CategoryChartData
from pptx.enum.chart import XL_CHART_TYPE

# Read data into a DataFrame (replace 'data.csv' with your DataFrame)
data = pd.read_csv('data.csv')

# Create a PowerPoint presentation object from an existing file
presentation = Presentation('existing_presentation.pptx')

# Create a slide for the bar chart
slide_layout = presentation.slide_layouts[5]  # You can choose a different layout if needed
slide = presentation.slides.add_slide(slide_layout)

# Define chart data
chart_data = CategoryChartData()
chart_data.categories = list(data['Category'])  # Replace 'Category' with your column name
chart_data.add_series('Series Name', (list(data['Value']),))  # Replace 'Value' with your column name

# Add a bar chart to the slide
x, y, cx, cy = Inches(2), Inches(2), Inches(6), Inches(4.5)  # Adjust the position and size of the chart
chart = slide.shapes.add_chart(
    XL_CHART_TYPE.BAR_CLUSTERED, x, y, cx, cy, chart_data
).chart

# Customize the appearance of the chart if needed
# chart.has_legend = True
# chart.legend.position = XL_LEGEND_POSITION.BOTTOM

# Save the modified presentation
presentation.save('modified_presentation.pptx')










import pandas as pd
from pptx import Presentation
from pptx.util import Inches
from io import BytesIO
import matplotlib.pyplot as plt

# Assuming you have a DataFrame named 'df' with data for the bar graph
# df = pd.DataFrame({'Category': ['A', 'B', 'C'], 'Value': [10, 20, 15]})

# Create a bar graph using pandas
ax = df.plot(kind='bar', x='Category', y='Value', legend=False)
plt.ylabel('Value')  # Set y-axis label
plt.xlabel('Category')  # Set x-axis label
plt.title('Bar Graph')  # Set title
plt.tight_layout()

# Save the plot to a BytesIO object
image_stream = BytesIO()
plt.savefig(image_stream, format='png')
image_stream.seek(0)
plt.close()

# Load the existing PowerPoint presentation
pptx_file = 'path_to_existing_pptx_file.pptx'
presentation = Presentation(pptx_file)

# Add a new slide to the presentation
slide_layout = presentation.slide_layouts[1]  # You can choose a different slide layout if needed
slide = presentation.slides.add_slide(slide_layout)

# Add the bar graph image to the slide
left = Inches(1)  # Adjust the left position of the image on the slide
top = Inches(1)   # Adjust the top position of the image on the slide
pic = slide.shapes.add_picture(image_stream, left, top, height=Inches(3))  # Set image height as needed

# Save the modified presentation
presentation.save('path_to_output_pptx_file.pptx')








import pandas as pd
from pptx import Presentation
from pptx.util import Inches
from pptx.chart.data import CategoryChartData
from pptx.enum.chart import XL_CHART_TYPE

# Load your data into a pandas DataFrame (replace this with your actual data source)
data = {
    'Category': ['A', 'B', 'C', 'D'],
    'Values': [10, 15, 8, 12]
}
df = pd.DataFrame(data)

# Load your existing PowerPoint presentation
presentation = Presentation("existing_presentation.pptx")

# Create a slide for the bar graph
slide_layout = presentation.slide_layouts[1]  # Choose the slide layout you want (1 corresponds to Title and Content layout)
slide = presentation.slides.add_slide(slide_layout)

# Set slide title
title = slide.shapes.title
title.text = "Bar Graph from DataFrame"

# Create a bar chart from the DataFrame
chart_data = CategoryChartData()
chart_data.categories = df['Category']
chart_data.add_series('Values', df['Values'])

x, y, cx, cy = Inches(2), Inches(2.5), Inches(6), Inches(3.5)
chart = slide.shapes.add_chart(
    XL_CHART_TYPE.BAR_CLUSTERED, x, y, cx, cy, chart_data
).chart

# Customize the chart (if needed)
# For example, you can set the chart title:
chart.has_title = True
chart.chart_title.text_frame.text = "Bar Chart Title"

# Save the modified presentation
presentation.save("modified_presentation.pptx")











# Sample predictions and actual labels (binary classification)
predictions = [0.2, 0.6, 0.8, 0.3, 0.7]
actual_labels = [0, 1, 1, 0, 1]

# Step 2: Generate Thresholds
thresholds = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]

# Step 3: Calculate TPR and FPR for Each Threshold
tpr_list = []
fpr_list = []

for threshold in thresholds:
    tp = sum((p >= threshold) and (a == 1) for p, a in zip(predictions, actual_labels))
    fn = sum((p < threshold) and (a == 1) for p, a in zip(predictions, actual_labels))
    fp = sum((p >= threshold) and (a == 0) for p, a in zip(predictions, actual_labels))
    tn = sum((p < threshold) and (a == 0) for p, a in zip(predictions, actual_labels))
    
    tpr = tp / (tp + fn)
    fpr = fp / (fp + tn)
    
    tpr_list.append(tpr)
    fpr_list.append(fpr)

# Step 4: Plot the ROC Curve
import matplotlib.pyplot as plt

plt.figure(figsize=(6, 6))
plt.plot(fpr_list, tpr_list, marker='o', linestyle='--', color='b')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve')
plt.grid(True)
plt.show()











import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LassoCV
from sklearn.feature_selection import SelectKBest, f_regression, RFE
from sklearn.ensemble import RandomForestRegressor
from sklearn.decomposition import PCA

# Load dataset
data = pd.read_csv('your_dataset.csv')
X = data.drop('target', axis=1)
y = data['target']

# Split dataset
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Filter method: SelectKBest with f_regression
filter_selector = SelectKBest(score_func=f_regression, k=10)
X_train_filtered = filter_selector.fit_transform(X_train, y_train)
X_test_filtered = filter_selector.transform(X_test)

# Wrapper method: RFE with RandomForest
rfe_selector = RFE(estimator=RandomForestRegressor(), n_features_to_select=10, step=1)
X_train_rfe = rfe_selector.fit_transform(X_train, y_train)
X_test_rfe = rfe_selector.transform(X_test)

# Embedded method: Lasso
lasso = LassoCV()
lasso.fit(X_train, y_train)
importance = pd.Series(lasso.coef_, index=X_train.columns).abs().sort_values(ascending=False)
selected_features = importance[importance > 0].index
X_train_lasso = X_train[selected_features]
X_test_lasso = X_test[selected_features]

# Dimensionality Reduction: PCA
pca = PCA(n_components=10)
X_train_pca = pca.fit_transform(X_train)
X_test_pca = pca.transform(X_test)

# Tree-Based: Feature Importance with RandomForest
rf = RandomForestRegressor()
rf.fit(X_train, y_train)
importance = pd.Series(rf.feature_importances_, index=X_train.columns).sort_values(ascending=False)
selected_features = importance.head(10).index
X_train_rf = X_train[selected_features]
X_test_rf = X_test[selected_features]



import pandas as pd

# Example DataFrame
data = {
    'contract_id': [1, 1, 1, 2, 2, 2],
    'date': ['2023-08-28', '2022-08-28', '2023-08-29', '2023-08-28', '2022-08-28', '2023-08-29'],
    'salary': [5000, 4500, 5200, 6000, 5800, 6200]
}

df = pd.DataFrame(data)

# Convert 'date' column to datetime
df['date'] = pd.to_datetime(df['date'])

df['year'] = df['date'].dt.year

# Pivot the data to have separate columns for current year and last year's salary
pivot_df = df.pivot_table(index=['contract_id', 'date'], columns='year', values='salary').reset_index()

# Rename columns for clarity
pivot_df.columns.name = None
pivot_df.rename(columns={2023: 'current_salary', 2022: 'last_year_salary'}, inplace=True)


pivot_df['salary_difference'] = pivot_df['current_salary'] - pivot_df['last_year_salary']








/* Step 1: Define the participant data */
data participant_data;
    input participant_id $ participant_date :yymmdd10.;
    format participant_date yymmdd10.;
    datalines;
12345 2023-10-01
67890 2023-09-15
... /* Add all 4000 participants here */
;
run;

/* Step 2: Connect to the DB2 table and fetch the required data */
proc sql;
    connect to db2 (database=your_db2_database user=your_username password=your_password);

    create table filtered_data as
    select * from connection to db2 (
        /* Subquery to find the max effective_date for each participant */
        select t1.participant_id,
               t1.effective_date,
               t1.other_columns /* Include other columns you need */
        from your_db2_table t1
        inner join (
            /* Filter participant IDs and dates */
            select participant_id, max(effective_date) as max_effective_date
            from your_db2_table
            where participant_id in (
                /* List of participant IDs */
                select participant_id from participant_data
            )
            and effective_date < (
                /* Corresponding participant_date */
                select participant_date
                from participant_data p
                where p.participant_id = your_db2_table.participant_id
            )
            group by participant_id
        ) t2
        on t1.participant_id = t2.participant_id
        and t1.effective_date = t2.max_effective_date
    );

    disconnect from db2;
quit;


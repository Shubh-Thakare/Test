/* Sort the DataFrame by ContractNumber and EffectiveDate */
proc sort data=YourDataFrame;
  by ContractNumber EffectiveDate;
run;

/* Create a new DataFrame with forward filled values */
data ForwardFilledDataFrame;
  set YourDataFrame;
  by ContractNumber EffectiveDate;

  /* Retain the last non-missing values within the same ContractNumber */
  retain LastCompanyName LastEffectiveDate;

  /* Update the retained values */
  if first.ContractNumber then do;
    LastCompanyName = CompanyName;
    LastEffectiveDate = EffectiveDate;
  end;

  /* Forward fill missing values with the retained values */
  if missing(CompanyName) then CompanyName = LastCompanyName;
  if missing(EffectiveDate) then EffectiveDate = LastEffectiveDate;

  /* Output the updated row */
  output;
  
  /* Clear retained values for the next iteration */
  if last.ContractNumber then call missing(LastCompanyName, LastEffectiveDate);
run;

/* Sort the ForwardFilledDataFrame by ContractNumber and EffectiveDate if necessary */
proc sort data=ForwardFilledDataFrame;
  by ContractNumber EffectiveDate;
run;





import pandas as pd

# Sample DataFrame
data = {
    'date': ['2023-01-01', '2023-01-02', '2023-01-03', '2023-01-04', '2023-01-05', '2023-01-06', '2023-01-07', '2023-01-08'],
    'column_with_duplicates': ['A', 'B', 'A', 'A', 'C', 'C', 'C', 'D']
}

df = pd.DataFrame(data)

# Step 1: Sort the DataFrame by the date column
df.sort_values(by='date', inplace=True)

# Step 2: Identify and mark duplicates in the specified column
df['is_duplicate'] = df['column_with_duplicates'].duplicated(keep='first')

# Step 3: Keep first occurrence of duplicates if they are in continuous rows, otherwise keep all duplicates
df['is_duplicate'] = df['is_duplicate'] & df['is_duplicate'].shift(-1, fill_value=False)

# Step 4: Drop the marked duplicate rows
result_df = df[~df['is_duplicate']].drop(columns=['is_duplicate'])

print(result_df)




import pandas as pd

# Sample DataFrame
data = {
    'date': ['2023-01-01', '2023-01-02', '2023-01-03', '2023-01-03', '2023-01-04', '2023-01-05', '2023-01-05'],
    'value': [1, 2, 3, 3, 4, 5, 5]
}

df = pd.DataFrame(data)

# Convert the 'date' column to datetime
df['date'] = pd.to_datetime(df['date'])

# Step 1: Sort the DataFrame by the 'date' column
df.sort_values(by='date', inplace=True)

# Step 2: Identify duplicates in the 'value' column
duplicates_mask = df['value'].duplicated(keep='first')

# Step 3: Keep the first row of each set of continuous duplicates and drop the rest
result_df = df[~(duplicates_mask & duplicates_mask.shift(-1))]

print(result_df)







import pandas as pd

# Sample DataFrame (replace this with your actual DataFrame)
data = {
    'date': ['2023-01-01', '2023-01-02', '2023-01-03', '2023-01-04', '2023-01-04', '2023-01-06', '2023-01-07'],
    'value': [1, 2, 3, 4, 4, 6, 7]
}

df = pd.DataFrame(data)

# Convert the 'date' column to datetime
df['date'] = pd.to_datetime(df['date'])

# Sort the DataFrame by the 'date' column
df.sort_values(by='date', inplace=True)

# Identify duplicates in the 'value' column
duplicates_mask = df['value'].duplicated(keep=False)

# Keep the first occurrence of duplicates if they are in continuous rows; otherwise, keep all duplicates
result_df = df.drop_duplicates(subset='value', keep='first' if duplicates_mask.all() else False)

print(result_df)
